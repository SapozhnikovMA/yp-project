{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Оглавление",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "name": "toxic_comments_NLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8s8Fj3Tedld"
      },
      "source": [
        "**Проект NLP**\n",
        "\n",
        "Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
        "\n",
        "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
        "\n",
        "Постройте модель со значением метрики качества *F1* не меньше 0.75."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvLTxIleedli"
      },
      "source": [
        "## Подготовка"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwsOMSSVedli",
        "outputId": "40227257-a732-4184-fe62-c2acd8962d19"
      },
      "source": [
        "# Загрузим библиотеки\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.svm import LinearSVC\n",
        "import lightgbm\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /home/jovyan/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "fvhHN4vledll",
        "outputId": "bbb20bb0-14e6-453a-91d1-b019f600ffc8"
      },
      "source": [
        "df = pd.read_csv('/datasets/toxic_comments.csv')\n",
        "df.info()\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 159571 entries, 0 to 159570\n",
            "Data columns (total 2 columns):\n",
            "text     159571 non-null object\n",
            "toxic    159571 non-null int64\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 2.4+ MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  toxic\n",
              "0  Explanation\\nWhy the edits made under my usern...      0\n",
              "1  D'aww! He matches this background colour I'm s...      0\n",
              "2  Hey man, I'm really not trying to edit war. It...      0\n",
              "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
              "4  You, sir, are my hero. Any chance you remember...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-Nv00jbedlm"
      },
      "source": [
        "### Предобработка датасета"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6t6rxyI8edlm",
        "outputId": "73db6984-e4ef-4ccd-b956-a49959c168b0"
      },
      "source": [
        "# Проведем предобработку\n",
        "display(df[df['text'].isna()])\n",
        "df[df.duplicated(subset=df.columns.to_list())].sort_values(by='text', ascending=False)\n",
        "# Все чисто!"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [text, toxic]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [text, toxic]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "217cELhGedlm",
        "outputId": "f007207d-bfed-4a7b-8d93-1ba0f9f76335"
      },
      "source": [
        "# Анализ датасета\n",
        "df.describe()\n",
        "# негативных твитов всего 10%"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>count</td>\n",
              "      <td>159571.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>mean</td>\n",
              "      <td>0.101679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>std</td>\n",
              "      <td>0.302226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>min</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25%</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50%</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75%</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>max</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               toxic\n",
              "count  159571.000000\n",
              "mean        0.101679\n",
              "std         0.302226\n",
              "min         0.000000\n",
              "25%         0.000000\n",
              "50%         0.000000\n",
              "75%         0.000000\n",
              "max         1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fB1-NtYDedln"
      },
      "source": [
        "**Вывод**\n",
        "- Пропусков и дублей - нет\n",
        "- Данные несбалансированы - 10% - негативные твиты."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwzzCzTaedln"
      },
      "source": [
        "### Чистка текста"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "M0jWrtxWedln",
        "outputId": "26d7c01e-b0fc-4dcd-99bc-84cf7d7ff00a"
      },
      "source": [
        "# Загрузим лемматизатор и проверим его\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "print(lemmatizer.lemmatize(\"bats\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwgXltewedlo"
      },
      "source": [
        "corpus = list(df['text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vd2c9XXsedlo"
      },
      "source": [
        "# Создали функцию для определения части речи\n",
        "def get_wordnet_pos(word):\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\n",
        "                \"N\": wordnet.NOUN,\n",
        "                \"V\": wordnet.VERB,\n",
        "                \"R\": wordnet.ADV}\n",
        "    return tag_dict.get(tag, wordnet.VERB)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1qFlENUedlo",
        "outputId": "0d7f4b25-56b6-494d-b5e7-9beea758007c"
      },
      "source": [
        "# Обработка текста: приведение к стррочным буквам, выделения лемм, удаление стоп-слов, регулярных выражений\n",
        "stop_words = set(stopwords.words('english'))\n",
        "def lemmatize(text):\n",
        "    lemmatized_output = ' '.join([lemmatizer.lemmatize(w.lower(), get_wordnet_pos(w)) for w in nltk.word_tokenize(text)])\n",
        "    without_stop_words = ' '.join([w for w in nltk.word_tokenize(lemmatized_output) if not w in stop_words])\n",
        "    text = re.sub(r'[^a-zA-Z]', ' ', without_stop_words)\n",
        "    return \" \".join(text.split())\n",
        "# Проверка\n",
        "lemmatize(corpus[2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hey man m really try edit war s guy constantly remove relevant information talk edits instead talk page seem care format actual info'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRpNN-jHedlp"
      },
      "source": [
        "**Выводы по обработке текста**\n",
        "- В тексте много ошибок, особенно в инвективной лексике. Сначала посылают на хер (с ошибкой в слове fcuk, fuckfuckfuck), а потом желают удачного дня - возможно такой твит ML запишет в положительный твит;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7d9izNsedlq"
      },
      "source": [
        "# Обработаем весь датасет\n",
        "df['lemm_text'] = df['text'].apply(lemmatize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "CHttojnTedlr",
        "outputId": "26632ef1-a458-4ab4-c3b7-93343afdaeb3"
      },
      "source": [
        "# Проверим результат\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>lemm_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>explanation edits make username hardcore metal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>d aww match background colour m seemingly stuc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>hey man m really try edit war s guy constantly...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>ca n t make real suggestion improvement wonder...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>sir hero chance remember page s</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  toxic  \\\n",
              "0  Explanation\\nWhy the edits made under my usern...      0   \n",
              "1  D'aww! He matches this background colour I'm s...      0   \n",
              "2  Hey man, I'm really not trying to edit war. It...      0   \n",
              "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
              "4  You, sir, are my hero. Any chance you remember...      0   \n",
              "\n",
              "                                           lemm_text  \n",
              "0  explanation edits make username hardcore metal...  \n",
              "1  d aww match background colour m seemingly stuc...  \n",
              "2  hey man m really try edit war s guy constantly...  \n",
              "3  ca n t make real suggestion improvement wonder...  \n",
              "4                    sir hero chance remember page s  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHQQpPF3edlr"
      },
      "source": [
        "**Вывод**\n",
        "- Стоп-слов нет, но остались буквы;\n",
        "- Глаголы в инфинитиве - все ок."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQryqNtuedlr"
      },
      "source": [
        "## Обучение"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vNSW1Yaedls"
      },
      "source": [
        "# Разделим данные на трейн и тест (75, 25)\n",
        "X = df.drop(['text', 'toxic'], axis=1)\n",
        "y = df['toxic']\n",
        "X_tr, X_t, y_tr, y_t = train_test_split(X, y, stratify=y, test_size=0.25)\n",
        "corpus_tr = X_tr['lemm_text'].values.astype('U')\n",
        "corpus_t = X_t['lemm_text'].values.astype('U')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FatjLhFnedls"
      },
      "source": [
        "# Подготовим мешок слов и TF-IDF\n",
        "count_vect = CountVectorizer()\n",
        "count_tf_idf = TfidfVectorizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X51Mu7_Bedlt",
        "outputId": "0f81743e-0105-4e81-ca63-35b73b53f585"
      },
      "source": [
        "X_tr = count_tf_idf.fit_transform(corpus_tr)\n",
        "X_t = count_tf_idf.transform(corpus_t)\n",
        "print(\"Размер матрицы:\", X_tr.shape)\n",
        "print(\"Размер матрицы:\", X_t.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Размер матрицы: (119678, 132432)\n",
            "Размер матрицы: (39893, 132432)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "P9LmxRbnedlt",
        "outputId": "6db7c226-5808-40bc-e955-c8bd44d43468"
      },
      "source": [
        "X_tr_c = count_vect.fit_transform(corpus_tr)\n",
        "X_t_c = count_vect.transform(corpus_t)\n",
        "print(\"Размер матрицы:\", X_tr_c.shape)\n",
        "print(\"Размер матрицы:\", X_t_c.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Размер матрицы: (119678, 132432)\n",
            "Размер матрицы: (39893, 132432)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIO6Xwxkedlt"
      },
      "source": [
        "### Логистическая регрессия"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGtomhUEedlu"
      },
      "source": [
        "# Создадим функцю для логистической регрессии\n",
        "def lr(features_tr, target_tr, features_val, target_val, C, cl_w):\n",
        "    lr = LogisticRegression(class_weight = cl_w, C=C, solver = 'liblinear', random_state=42)\n",
        "    lr.fit(features_tr, target_tr)\n",
        "    predictions = lr.predict(features_val)\n",
        "    precision = precision_score(target_val, predictions)\n",
        "    recall = recall_score(target_val, predictions)\n",
        "    f1 = f1_score(target_val, predictions)\n",
        "    print(\"F1 = {:.2f} | Точность = {:.3f}, Полнота = {:.3f}\".format(\n",
        "        f1, precision, recall))\n",
        "    print(confusion_matrix(target_val, predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "-_SRnFvpedlu",
        "outputId": "261a0bc6-f38c-4386-e1e1-1cbe3bf0bf33"
      },
      "source": [
        "lr(X_tr, y_tr, X_t, y_t, 10, None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 = 0.78 | Точность = 0.879, Полнота = 0.704\n",
            "[[35442   395]\n",
            " [ 1199  2857]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "QK5tWyZuedlv",
        "outputId": "8b86fd60-29c8-4c90-dd1e-7193394a2d75"
      },
      "source": [
        "lr(X_tr_c, y_tr, X_t_c, y_t, 10, None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 = 0.70 | Точность = 0.895, Полнота = 0.571\n",
            "[[35566   271]\n",
            " [ 1741  2315]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTp6huh0edlv"
      },
      "source": [
        "### LinearSVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOkDFbAXedlv"
      },
      "source": [
        "# Создадим функцю для LinearSVC\n",
        "def lsvc(features_tr, target_tr, features_val, target_val, C, cl_w):\n",
        "    lsvc = LinearSVC(class_weight = cl_w, C=C, random_state=42)\n",
        "    lsvc.fit(features_tr, target_tr)\n",
        "    predictions = lsvc.predict(features_val)\n",
        "    precision = precision_score(target_val, predictions)\n",
        "    recall = recall_score(target_val, predictions)\n",
        "    f1 = f1_score(target_val, predictions)\n",
        "    print(\"F1 = {:.2f} | Точность = {:.3f}, Полнота = {:.3f}\".format(\n",
        "        f1, precision, recall))\n",
        "    print(confusion_matrix(target_val, predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1zG5Fvmedlw",
        "outputId": "289b3b86-9b20-45bf-c82f-2dd3ba1e3962"
      },
      "source": [
        "lsvc(X_tr, y_tr, X_t, y_t, 0.8, None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 = 0.79 | Точность = 0.885, Полнота = 0.707\n",
            "[[35463   374]\n",
            " [ 1190  2866]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "_D8wjkiJedlw",
        "outputId": "6967ea09-c676-40a2-9116-eecb0d26c6fc"
      },
      "source": [
        "lsvc(X_tr_c, y_tr, X_t_c, y_t, 1, None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 = 0.75 | Точность = 0.779, Полнота = 0.732\n",
            "[[34995   842]\n",
            " [ 1087  2969]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yrRFcZJedlw"
      },
      "source": [
        "### RandomForest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZM1geg7edlw"
      },
      "source": [
        "# Создадим функцю для forest\n",
        "def forest(features_tr, target_tr, features_val, target_val):\n",
        "    forest = RandomForestClassifier()\n",
        "    forest.fit(features_tr, target_tr)\n",
        "    predictions = forest.predict(features_val)\n",
        "    precision = precision_score(target_val, predictions)\n",
        "    recall = recall_score(target_val, predictions)\n",
        "    f1 = f1_score(target_val, predictions)\n",
        "    print(\"F1 = {:.2f} | Точность = {:.3f}, Полнота = {:.3f}\".format(\n",
        "        f1, precision, recall))\n",
        "    print(confusion_matrix(target_val, predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "cDZKcNZ2edlx",
        "outputId": "ff9a7c78-3daf-4482-b211-33a6151319b7"
      },
      "source": [
        "forest(X_tr, y_tr, X_t, y_t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "F1 = 0.65 | Точность = 0.913, Полнота = 0.508\n",
            "[[35641   196]\n",
            " [ 1996  2060]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "6brohr3Qedlx",
        "outputId": "e77b5dc1-d8ba-4b98-9759-ef3bc552e813"
      },
      "source": [
        "forest(X_tr_c, y_tr, X_t_c, y_t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "F1 = 0.65 | Точность = 0.889, Полнота = 0.509\n",
            "[[35580   257]\n",
            " [ 1993  2063]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfMuRG61edlx"
      },
      "source": [
        "### LGBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbalT0C-edlx"
      },
      "source": [
        "# Создадим функцю для LGBMClassifier\n",
        "def lgbm(features_tr, target_tr, features_val, target_val, lr):\n",
        "    lgbm = LGBMClassifier(learning_rate=lr, random_state=42)\n",
        "    lgbm.fit(features_tr, target_tr, eval_set=[(features_val, target_val)], eval_metric='F1')\n",
        "    predictions = lgbm.predict(features_val)\n",
        "    precision = precision_score(target_val, predictions)\n",
        "    recall = recall_score(target_val, predictions)\n",
        "    f1 = f1_score(target_val, predictions)\n",
        "    print(\"F1 = {:.2f} | Точность = {:.3f}, Полнота = {:.3f}\".format(\n",
        "        f1, precision, recall))\n",
        "    print(confusion_matrix(target_val, predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YS6UdBk6edly"
      },
      "source": [
        "#lgbm(X_tr, y_tr, X_t, y_t, 0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RM63Dsoedly"
      },
      "source": [
        "## Выводы"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "oWs7j8Oredly",
        "outputId": "878f8778-f8e4-427a-bb8c-f1bb17115460"
      },
      "source": [
        "# Сравним результаты тестирования моделей\n",
        "data1 = {'model':['log_reg_tf', 'log_reg_bag', 'linearSVC_tf', 'linearSVC_bag', 'rand_forest_tf', 'rand_forest_bag', 'lgbm_tf'], 'F1':[0.78, 0.70, 0.79, 0.75, 0.65, 0.65, 0.78]}\n",
        "table = pd.DataFrame(data1)\n",
        "table.sort_values(by='F1',ascending=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>linearSVC_tf</td>\n",
              "      <td>0.79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>log_reg_tf</td>\n",
              "      <td>0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>lgbm_tf</td>\n",
              "      <td>0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>linearSVC_bag</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>log_reg_bag</td>\n",
              "      <td>0.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>rand_forest_tf</td>\n",
              "      <td>0.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>rand_forest_bag</td>\n",
              "      <td>0.65</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             model    F1\n",
              "2     linearSVC_tf  0.79\n",
              "0       log_reg_tf  0.78\n",
              "6          lgbm_tf  0.78\n",
              "3    linearSVC_bag  0.75\n",
              "1      log_reg_bag  0.70\n",
              "4   rand_forest_tf  0.65\n",
              "5  rand_forest_bag  0.65"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vFAmeh7edlz"
      },
      "source": [
        "**Вывод:**\n",
        "- Лучшая модель - LinearSVC - 0.79 (С - 0.8), меньше всего ошибок FP и FN;\n",
        "- Модели логист.регрессия и LGBMClassifier дали близкие результаты, но с разницей в точности;\n",
        "- TF-IDF дает лучшие результаты, чем bag_of_words;\n",
        "- В твитах много ошибок - сначала ругательство с ошибкой, а потом Nice day, скорее всего ML определит как положительный твит:)\n",
        "- Разбивка на биграммы и триграммы - ухудшает модель;"
      ]
    }
  ]
}